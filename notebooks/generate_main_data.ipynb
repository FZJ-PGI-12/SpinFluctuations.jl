{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Set Overview Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using QAOA, Distributions, Interpolations\n",
    "using DataFrames, Arrow, HDF5, Printf\n",
    "using PyPlot\n",
    "PyPlot.plt.style.use(\"./paper.mplstyle\")\n",
    "\n",
    "using PyCall\n",
    "np = pyimport(\"numpy\")\n",
    "\n",
    "PATH = \"/home/ubuntu/Archives/\"\n",
    "PLOT_PATH = \"/home/ubuntu/Archives/plots/SK_model/paper/\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise, SpinFluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.show(io::IO, f::Float64) = @printf(io, \"%1.4f\", f)\n",
    "Base.show(io::IO, ::MIME\"text/latex\", df::AbstractDataFrame) = show(df, backend=:html, show_row_number=true, highlighters=:tf_html_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 9\n",
    "N = 11\n",
    "N = 13\n",
    "N = 15\n",
    "N = 17\n",
    "N = 19\n",
    "\n",
    "patterns_dict = Dict(\n",
    "    9  => r\"random_SK_instance_N_9_seed_(\\d+)\\.h5\",\n",
    "    11 => r\"random_SK_instance_N_11_seed_(\\d+)\\.h5\",\n",
    "    13 => r\"random_SK_instance_N_13_seed_(\\d+)\\.h5\",\n",
    "    15 => r\"random_SK_instance_N_15_seed_(\\d+)\\.h5\",\n",
    "    17 => r\"random_SK_instance_N_17_seed_(\\d+)\\.h5\",\n",
    "    19 => r\"random_SK_instance_N_19_seed_(\\d+)\\.h5\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npts = 2048\n",
    "# npts = 2^13\n",
    "coarse_times = range(0, 1, npts + 1)\n",
    "exact_times = range(0, 1, 33);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = \"small_gaps\"\n",
    "# subdir = \"large_gaps\"\n",
    "folder_name = PATH * @sprintf(\"data/SK_model/N_%i/%s/\", N, subdir)\n",
    "instance_names = readdir(folder_name)\n",
    "filter!(x -> !occursin(\"results\", x), instance_names)\n",
    "filter!(x -> !occursin(\"undecided\", x), instance_names)\n",
    "filter!(x -> !occursin(\"frustrated\", x), instance_names)\n",
    "filter!(x -> !occursin(\"main_df\", x), instance_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_frustrated_spins_seeds = h5read(folder_name * @sprintf(\"most_undecided_spins_N_%i.h5\", N), @sprintf(\"T_final_%.0f_tol_1e%.0f/seeds\", 32768., log10(1e-6)))\n",
    "# most_frustrated_spins_idxs = h5read(folder_name * @sprintf(\"most_undecided_spins_N_%i.h5\", N), @sprintf(\"T_final_%.0f_tol_1e%.0f/spin_idxs\", 32768., log10(1e-6)));\n",
    "# most_frustrated_spins = Dict(zip(most_frustrated_spins_seeds, eachrow(most_frustrated_spins_idxs)))\n",
    "# df_filename = \"main_df_undecided\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frustrated_spins_seeds = h5read(folder_name * @sprintf(\"most_frustrated_spins_N_%i.h5\", N), @sprintf(\"T_final_%.0f_tol_1e%.0f/seeds\", 32768., log10(1e-6)))\n",
    "most_frustrated_spins_idxs = h5read(folder_name * @sprintf(\"most_frustrated_spins_N_%i.h5\", N), @sprintf(\"T_final_%.0f_tol_1e%.0f/spin_idxs\", 32768., log10(1e-6)));\n",
    "most_frustrated_spins = Dict(zip(most_frustrated_spins_seeds, eachrow(most_frustrated_spins_idxs)))\n",
    "df_filename = \"main_df_frustrated\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_seeds = []\n",
    "\n",
    "mean_fields = Dict()\n",
    "all_magnetizations = Dict()\n",
    "mean_scaled_flucs = Dict()\n",
    "most_frustrated_flucs = Dict()\n",
    "\n",
    "all_Hs = Dict()\n",
    "all_eigenvals = Dict()\n",
    "all_eigenstates = Dict()\n",
    "\n",
    "# for (k, instance_name) in enumerate(instance_names[310:319]) # instance \"23320\"\n",
    "for (k, instance_name) in enumerate(instance_names)\n",
    "    seed = match(patterns_dict[N], instance_name)[1]    \n",
    "    print(k, \", \")\n",
    "\n",
    "    # eigenvalues and -vectors\n",
    "    λ = h5read(folder_name * instance_name, \"exact_ARPACK_LM_eigvals\")\n",
    "    all_eigvecs = h5read(folder_name * instance_name, \"exact_ARPACK_LM_lowest_eigvecs\")\n",
    "\n",
    "    J_mat = h5read(folder_name * instance_name, \"J\")\n",
    "    mf_problem = Problem(0, J_mat)\n",
    "\n",
    "    # # mean-field solutions\n",
    "    T_final = 32768.\n",
    "    tol = 1e-6\n",
    "    mf_sol = h5read(folder_name * \"results_\" * instance_name, @sprintf(\"mean_field_sol_T_final_%.0f_tol_1e%.0f\", T_final, log10(tol)))\n",
    "    sigma_star = sign.(mf_sol)\n",
    "    h = mf_problem.local_fields\n",
    "    J = mf_problem.couplings\n",
    "    E_star = sum([-h[l] * sigma_star[l] for l in 1:N-1]) + sum([-J[i, j] * sigma_star[i] * sigma_star[j] for i in 1:N-1 for j in (i+1):N-1]) \n",
    "    \n",
    "    # continue if mean-fields finds optimal solution\n",
    "    if isapprox(E_star, λ[1, end], atol=1e-5)\n",
    "        continue\n",
    "    end\n",
    "        \n",
    "    sol_t = h5read(folder_name * \"results_\" * instance_name, @sprintf(\"mean_field_T_final_%.0f_tol_1e%.0f/times\", T_final, log10(tol)))\n",
    "    sol_u = h5read(folder_name * \"results_\" * instance_name, @sprintf(\"mean_field_T_final_%.0f_tol_1e%.0f/trajectories\", T_final, log10(tol)))\n",
    "\n",
    "    nx_coarse, ny_coarse, nz_coarse = [n_coarse(n_vals(xyz, sol_u), sol_t, coarse_times) for xyz in 1:3]\n",
    "    mean_fields[seed] = [nx_coarse, ny_coarse, nz_coarse]\n",
    "    S_vals = [transpose(reduce(hcat, [nx_coarse[:, k], ny_coarse[:, k], nz_coarse[:, k]])) |> Matrix for k in 1:npts+1]\n",
    "    magnetizations = reduce(hcat, map(S -> magnetization(S, mf_problem.local_fields, mf_problem.couplings), S_vals))\n",
    "    all_magnetizations[seed] = magnetizations    \n",
    "\n",
    "    # fluctuations\n",
    "    T_final = 32000\n",
    "    # T_final = 2^16\n",
    "    tol = 1e-8\n",
    "    all_flucs = h5read(folder_name * \"results_\" * instance_name, @sprintf(\"fluctuations_T_final_%.0f_tol_1e%.0f_npts_%i\", T_final, log10(tol), npts))\n",
    "    lyapunov_exponent = sum(all_flucs, dims=1)\n",
    "    if sum(lyapunov_exponent) |> abs < 1e4 # discard non-converged ones\n",
    "\n",
    "        # get \"normal\" trajectories\n",
    "        # regular_trajectories = filter!(x -> x != most_frustrated_spins[seed][1], collect(1:N-1))\n",
    "        # regular_trajectories = filter!(x -> x != most_frustrated_spins[seed][2], regular_trajectories)\n",
    "\n",
    "        scale_factors = [1 .+ abs.(complex_coordinate(i, mean_fields[seed]...)).^2 for i in 1:N-1]\n",
    "        # mean_scaled_flucs[seed] = mean([scale_factors[i].^2 .* all_flucs[i, :] for i in regular_trajectories], dims=1)[1]\n",
    "        mean_scaled_flucs[seed] = mean([scale_factors[i].^2 .* all_flucs[i, :] for i in 1:N-1], dims=1)[1]\n",
    "\n",
    "        # keep the two most frustrated spins\n",
    "        most_frustrated_flucs[seed] = [all_flucs[most_frustrated_spins[seed][1], :], all_flucs[most_frustrated_spins[seed][2], :]]\n",
    "    end\n",
    "\n",
    "    # adiabatic theorem...\n",
    "    H_x = SpinFluctuations.hamiltonian(1, 0, mf_problem.local_fields, mf_problem.couplings)\n",
    "    H_z = SpinFluctuations.hamiltonian(0, 1, mf_problem.local_fields, mf_problem.couplings)\n",
    "    all_Hs[seed] = [H_x, H_z]\n",
    "\n",
    "    eigenstate(n) = [all_eigvecs[k, :, n] for k in 1:length(exact_times)]\n",
    "    num_eig_vecs = size(all_eigvecs)[3]\n",
    "    all_eigenstates[seed] = [eigenstate(n) for n in 1:num_eig_vecs]\n",
    "    all_eigenvals[seed] = [λ[n, :] for n in 1:num_eig_vecs]\n",
    "\n",
    "    push!(ordered_seeds, seed)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_seeds |> size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minigap_locs = Dict()\n",
    "# all_adiabatic_fracs = Dict()\n",
    "all_overlaps = Dict()\n",
    "all_gaps = Dict()\n",
    "all_frustrated_flucs = Dict()\n",
    "all_inv_mags = Dict()\n",
    "seeds_to_max_fracs = Dict()\n",
    "\n",
    "for seed in ordered_seeds\n",
    "    try\n",
    "        λs = all_eigenvals[seed]\n",
    "        mingap = minimum(λs[2] .- λs[1])\n",
    "        gap_idx = findfirst(x -> x == mingap, λs[2] .- λs[1]) \n",
    "        gaploc = exact_times[gap_idx]\n",
    "        minigap_locs[seed] = gaploc\n",
    "        \n",
    "        nx_coarse, ny_coarse, nz_coarse = mean_fields[seed]\n",
    "        \n",
    "        all_frustrated_flucs[seed] = []\n",
    "        top_idx = most_frustrated_spins[seed][1]\n",
    "        scale_factor = 1 .+ abs.(complex_coordinate(top_idx, mean_fields[seed]...)).^2\n",
    "        push!(all_frustrated_flucs[seed], scale_factor.^2 .* most_frustrated_flucs[seed][1])\n",
    "\n",
    "        sec_idx = most_frustrated_spins[seed][2]\n",
    "        scale_factor = 1 .+ abs.(complex_coordinate(sec_idx, mean_fields[seed]...)).^2\n",
    "        push!(all_frustrated_flucs[seed], scale_factor.^2 .* most_frustrated_flucs[seed][2])   \n",
    "        \n",
    "        H_x, H_z = all_Hs[seed]\n",
    "        eigenstates = all_eigenstates[seed]\n",
    "        \n",
    "        overlap(n, H) = [eigenstates[n][k]' * H * eigenstates[1][k] for k in 1:length(exact_times)]\n",
    "        # frac_n(n) = abs.(overlap(n, H_z) .- overlap(n, H_x)) ./ (λs[n] .- λs[1])\n",
    "        \n",
    "        # all_adiabatic_fracs[seed] = [frac_n(n) for n in 2:5]\n",
    "        # all_adiabatic_fracs[seed] = [frac_n(n) for n in 2:3]\n",
    "        all_overlaps[seed] = [abs.(overlap(n, H_z) .- overlap(n, H_x)) for n in 2:3]\n",
    "        all_gaps[seed] = [1 ./ (λs[n] .- λs[1]) for n in 2:3]\n",
    "        \n",
    "        # seeds_to_max_fracs[seed] = maximum(all_adiabatic_fracs[seed][1])\n",
    "        seeds_to_max_fracs[seed] = maximum(all_overlaps[seed][1] .* (all_gaps[seed][1]).^2)\n",
    "    catch err\n",
    "        println(err)\n",
    "        println(seed)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_and_max_fracs = sort([(k, v) for (k, v) in seeds_to_max_fracs], by=x->x[2]) |> reverse;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write DataFrame with Arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_df = DataFrame(seed=String[], minigap_locs=Float64[], \n",
    "#                     eigvals=Vector[], eigstates=Vector[],\n",
    "#                     scaled_most_frustrated_flucs=Vector[], adiabatic_fracs=Vector[], mean_scaled_flucs=Vector[], \n",
    "#                     mean_fields=Vector[], magnetizations=Matrix[])\n",
    "# for (seed, _) in seeds_and_max_fracs\n",
    "#     push!(main_df, [seed, minigap_locs[seed], \n",
    "#                     all_eigenvals[seed], all_eigenstates[seed],\n",
    "#                     all_frustrated_flucs[seed], all_adiabatic_fracs[seed], mean_scaled_flucs[seed], \n",
    "#                     mean_fields[seed], all_magnetizations[seed]])\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = DataFrame(seed=String[], minigap_locs=Float64[], \n",
    "                    eigvals=Vector[], eigstates=Vector[],\n",
    "                    scaled_most_frustrated_flucs=Vector[], overlaps=Vector[], gaps=Vector[], mean_scaled_flucs=Vector[], \n",
    "                    mean_fields=Vector[], magnetizations=Matrix[])\n",
    "for (seed, _) in seeds_and_max_fracs\n",
    "    push!(main_df, [seed, minigap_locs[seed], \n",
    "                    all_eigenvals[seed], all_eigenstates[seed],\n",
    "                    all_frustrated_flucs[seed], all_overlaps[seed], all_gaps[seed], mean_scaled_flucs[seed], \n",
    "                    mean_fields[seed], all_magnetizations[seed]])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name * df_filename * \".arrow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arrow.write(folder_name * df_filename * \".arrow\", main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_df = DataFrame(Arrow.Table(folder_name * \"main_df.arrow\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
